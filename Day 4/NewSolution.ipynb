{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1190,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Matplotlib defaults\n",
    "plt.style.use(\"seaborn-whitegrid\")\n",
    "plt.rc(\"figure\", autolayout=True)\n",
    "plt.rc(\n",
    "    \"axes\",\n",
    "    labelweight=\"bold\",\n",
    "    labelsize=\"large\",\n",
    "    titleweight=\"bold\",\n",
    "    titlesize=14,\n",
    "    titlepad=10,\n",
    ")\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1192,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../Datasets/\"\n",
    "Train = pd.read_csv(path + '/Historical-transaction-data.csv')\n",
    "StoreInfo = pd.read_csv(path + '/Store-info.csv')\n",
    "Testing = pd.read_csv(path + '/Testing-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1193,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train = Train.merge(StoreInfo, on='shop_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1194,
   "metadata": {},
   "outputs": [],
   "source": [
    "Testing.drop(\"shop_profile\", axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1195,
   "metadata": {},
   "outputs": [],
   "source": [
    "Submission_testing = Testing.copy()\n",
    "Submission_testing = Submission_testing.merge(Train, on='shop_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1196,
   "metadata": {},
   "outputs": [],
   "source": [
    "Submission_testing.drop(\"shop_profile\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train.to_csv('CombinedData.csv', index=False)\n",
    "# Submission_testing.to_csv('SubmissionData.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1198,
   "metadata": {},
   "outputs": [],
   "source": [
    "redundant_cols = ['customer_id', 'transaction_date']\n",
    "\n",
    "Train.drop(redundant_cols, axis=1, inplace=True)\n",
    "Submission_testing.drop(redundant_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1199,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_nom = ['item_description',\"shop_id\", \"shop_profile\", \"invoice_id\"]\n",
    "\n",
    "for feature in features_nom:\n",
    "    Train[feature] = Train[feature].astype(\"category\")\n",
    "    if feature == \"shop_profile\":\n",
    "        continue\n",
    "    Submission_testing[feature] = Submission_testing[feature].astype(\"category\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1200,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train[\"shop_id\"] = Train[\"shop_id\"].str.replace(\"SHOP\", \"\").astype(int).astype(\"category\")\n",
    "Submission_testing[\"shop_id\"] = Submission_testing[\"shop_id\"].str.replace(\"SHOP\", \"\").astype(int).astype(\"category\")\n",
    "StoreInfo[\"shop_id\"] = StoreInfo[\"shop_id\"].str.replace(\"SHOP\", \"\").astype(int).astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1201,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove rows with null values for item_description or shop_profile\n",
    "Train = Train.dropna(subset=['shop_profile'], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1202,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "#import simpleimputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "Submission_testing['shop_profile'] = 'default_value'\n",
    "ct = ColumnTransformer([(\"SimpleImputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\"), [\"item_description\"])], remainder=\"passthrough\")\n",
    "\n",
    "Train = pd.DataFrame(ct.fit_transform(Train), columns=Train.columns)\n",
    "\n",
    "Submission_testing = pd.DataFrame(ct.transform(Submission_testing), columns=Train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace values in the \"item_description\" column of the Train dataframe\n",
    "Train['item_description'] = Train['item_description'].str.lower()\n",
    "Train.loc[Train['item_description'].str.contains('milk', case=False), 'item_description'] = 'MILK'\n",
    "Train.loc[Train['item_description'].str.contains('water', case=False), 'item_description'] = 'WATER'\n",
    "Train.loc[Train['item_description'].str.contains('missing', case=False), 'item_description'] = 'MISSING'\n",
    "Train.loc[~Train['item_description'].str.contains('MILK|WATER|MISSING', case=False), 'item_description'] = 'DRINK'\n",
    "\n",
    "# Replace values in the \"item_description\" column of the Submission_testing dataframe\n",
    "Submission_testing['item_description'] = Submission_testing['item_description'].str.lower()\n",
    "Submission_testing.loc[Submission_testing['item_description'].str.contains('milk', case=False), 'item_description'] = 'MILK'\n",
    "Submission_testing.loc[Submission_testing['item_description'].str.contains('water', case=False), 'item_description'] = 'WATER'\n",
    "Submission_testing.loc[Submission_testing['item_description'].str.contains('missing', case=False), 'item_description'] = 'MISSING'\n",
    "Submission_testing.loc[~Submission_testing['item_description'].str.contains('MILK|WATER|MISSING', case=False), 'item_description'] = 'DRINK'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1204,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train.drop_duplicates(inplace=True)\n",
    "Submission_testing.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop invoice_id column from both dataframes\n",
    "Train.drop(\"invoice_id\", axis=1, inplace=True)\n",
    "Submission_testing.drop([\"invoice_id\", \"shop_profile\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1206,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_columns = [\"shop_id\", \"item_description\", \"shop_profile\"]\n",
    "\n",
    "for col in Train.columns:\n",
    "    if col not in category_columns:\n",
    "        Train[col] = Train[col].astype(\"int64\")\n",
    "        Submission_testing[col] = Submission_testing[col].astype(\"int64\")\n",
    "    else:\n",
    "        Train[col] = Train[col].astype(\"category\")\n",
    "        if col == \"shop_profile\":\n",
    "            continue\n",
    "        Submission_testing[col] = Submission_testing[col].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppose x1 and x3 column should have a minimum of zero, define the acceptable ranges for each column\n",
    "\n",
    "ranges = {'quantity_sold': (0, np.inf)}\n",
    "\n",
    "# loop over each column and adjust the values outside the acceptable range\n",
    "\n",
    "for col, (min_val, max_val) in ranges.items():\n",
    "    Train[col] = np.clip(Train[col], min_val, max_val)\n",
    "    Submission_testing[col] = np.clip(Submission_testing[col], min_val, max_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_thresholds(dataframe, column_name, q1=0.05, q2=0.95):\n",
    "    quartile1 = dataframe[column_name].quantile(0.05)\n",
    "    quartile3 = dataframe[column_name].quantile(0.95)\n",
    "    IQR = quartile3 - quartile1\n",
    "    up_limit = quartile3 + 1.5*IQR\n",
    "    low_limit = quartile1 - 1.5*IQR\n",
    "    return low_limit, up_limit\n",
    "\n",
    "def check_outlier(dataframe, column_name):\n",
    "    low_limit, up_limit = outlier_thresholds(dataframe, column_name)\n",
    "    if dataframe[(dataframe[column_name] < low_limit) | (dataframe[column_name] > up_limit)].any(axis=None):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def replace_with_thresholds(dataframe, column_name):\n",
    "    low_limit, up_limit = outlier_thresholds(dataframe, column_name)\n",
    "    dataframe.loc[(dataframe[column_name] < low_limit), column_name] = low_limit\n",
    "    dataframe.loc[(dataframe[column_name] > up_limit), column_name] = up_limit\n",
    "    \n",
    "def remove_outliers(df):\n",
    "    numeric_columns = df.select_dtypes(include=['int64', 'float64', 'int32', 'float32']).columns\n",
    "    for col in numeric_columns:\n",
    "        print(col, check_outlier(df, col))\n",
    "        if check_outlier(df, col):\n",
    "            replace_with_thresholds(df, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "item_price         363.995483\n",
       "quantity_sold      374.858178\n",
       "shop_area_sq_ft      2.973588\n",
       "dtype: float64"
      ]
     },
     "execution_count": 1209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train.kurt(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_price</th>\n",
       "      <th>quantity_sold</th>\n",
       "      <th>shop_area_sq_ft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>351762.000000</td>\n",
       "      <td>351762.000000</td>\n",
       "      <td>351762.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>209.261958</td>\n",
       "      <td>1.945378</td>\n",
       "      <td>632.962836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>169.497265</td>\n",
       "      <td>1.667743</td>\n",
       "      <td>123.672885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>298.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>605.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>220.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>617.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>220.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>676.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17400.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>1077.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          item_price  quantity_sold  shop_area_sq_ft\n",
       "count  351762.000000  351762.000000    351762.000000\n",
       "mean      209.261958       1.945378       632.962836\n",
       "std       169.497265       1.667743       123.672885\n",
       "min        35.000000       0.000000       298.000000\n",
       "25%       100.000000       1.000000       605.000000\n",
       "50%       220.000000       2.000000       617.000000\n",
       "75%       220.000000       2.000000       676.000000\n",
       "max     17400.000000     101.000000      1077.000000"
      ]
     },
     "execution_count": 1210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_price True\n",
      "quantity_sold True\n",
      "shop_area_sq_ft False\n",
      "item_price True\n",
      "quantity_sold True\n",
      "shop_area_sq_ft False\n"
     ]
    }
   ],
   "source": [
    "remove_outliers(Train)\n",
    "remove_outliers(Submission_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "item_price         9.556541\n",
       "quantity_sold      8.931670\n",
       "shop_area_sq_ft    2.973588\n",
       "dtype: float64"
      ]
     },
     "execution_count": 1212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train.kurt(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_price</th>\n",
       "      <th>quantity_sold</th>\n",
       "      <th>shop_area_sq_ft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>351762.000000</td>\n",
       "      <td>351762.000000</td>\n",
       "      <td>351762.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>207.340482</td>\n",
       "      <td>1.902592</td>\n",
       "      <td>632.962836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>148.884035</td>\n",
       "      <td>1.140813</td>\n",
       "      <td>123.672885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>298.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>605.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>220.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>617.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>220.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>676.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1102.500000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>1077.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          item_price  quantity_sold  shop_area_sq_ft\n",
       "count  351762.000000  351762.000000    351762.000000\n",
       "mean      207.340482       1.902592       632.962836\n",
       "std       148.884035       1.140813       123.672885\n",
       "min        35.000000       0.000000       298.000000\n",
       "25%       100.000000       1.000000       605.000000\n",
       "50%       220.000000       2.000000       617.000000\n",
       "75%       220.000000       2.000000       676.000000\n",
       "max      1102.500000       8.500000      1077.000000"
      ]
     },
     "execution_count": 1213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create price-related features\n",
    "Train['total_sales']= Train['item_price'] * Train['quantity_sold']\n",
    "Submission_testing['total_sales']= Submission_testing['item_price'] * Submission_testing['quantity_sold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frequency encode the item_description column\n",
    "\n",
    "item_description_freq = Train.groupby('item_description').size()/len(Train)\n",
    "# mapping the encoded values to the Train and Submission_testing dataframes\n",
    "Train['item_description_freq'] = Train['item_description'].map(item_description_freq)\n",
    "Submission_testing['item_description_freq'] = Submission_testing['item_description'].map(item_description_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the item_description column and month column from both dataframes\n",
    "Train.drop([\"item_description\"], axis=1, inplace=True)\n",
    "Submission_testing.drop([\"item_description\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_price</th>\n",
       "      <th>quantity_sold</th>\n",
       "      <th>shop_area_sq_ft</th>\n",
       "      <th>shop_profile</th>\n",
       "      <th>total_sales</th>\n",
       "      <th>item_description_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>220.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>678</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>440.0</td>\n",
       "      <td>0.846726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>112</td>\n",
       "      <td>220.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>668</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>440.0</td>\n",
       "      <td>0.846726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>160.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>678</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>320.0</td>\n",
       "      <td>0.846726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>150.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>678</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>300.0</td>\n",
       "      <td>0.846726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>112</td>\n",
       "      <td>210.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>668</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>0.012887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>90</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>730</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.082001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>47</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>528</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.846726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>47</td>\n",
       "      <td>220.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>528</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>440.0</td>\n",
       "      <td>0.846726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>22</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>735</td>\n",
       "      <td>High</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.846726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>22</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>735</td>\n",
       "      <td>High</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.846726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    shop_id  item_price  quantity_sold  shop_area_sq_ft shop_profile  \\\n",
       "0         8       220.0            2.0              678     Moderate   \n",
       "1       112       220.0            2.0              668     Moderate   \n",
       "2         8       160.0            2.0              678     Moderate   \n",
       "3         8       150.0            2.0              678     Moderate   \n",
       "4       112       210.0            5.0              668     Moderate   \n",
       "..      ...         ...            ...              ...          ...   \n",
       "109      90        70.0            1.0              730     Moderate   \n",
       "111      47        60.0            1.0              528     Moderate   \n",
       "112      47       220.0            2.0              528     Moderate   \n",
       "113      22        60.0            2.0              735         High   \n",
       "114      22       100.0            2.0              735         High   \n",
       "\n",
       "     total_sales item_description_freq  \n",
       "0          440.0              0.846726  \n",
       "1          440.0              0.846726  \n",
       "2          320.0              0.846726  \n",
       "3          300.0              0.846726  \n",
       "4         1050.0              0.012887  \n",
       "..           ...                   ...  \n",
       "109         70.0              0.082001  \n",
       "111         60.0              0.846726  \n",
       "112        440.0              0.846726  \n",
       "113        120.0              0.846726  \n",
       "114        200.0              0.846726  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 1217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new feature for the fraction of  entries by each shop_id\n",
    "train_shop_id_counts = Train['shop_id'].value_counts(normalize=True)\n",
    "Train['shop_id_counts'] = Train['shop_id'].map(train_shop_id_counts)\n",
    "\n",
    "submit_shop_id_counts = Submission_testing['shop_id'].value_counts(normalize=True)\n",
    "Submission_testing['shop_id_counts'] = Submission_testing['shop_id'].map(submit_shop_id_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a feature for the mean item_price by each shop_id\n",
    "\n",
    "train_shop_price_mean = Train.groupby('shop_id')['item_price'].mean()\n",
    "Train['shop_price_mean'] = Train['shop_id'].map(train_shop_price_mean)\n",
    "\n",
    "submit_shop_price_mean = Submission_testing.groupby('shop_id')['item_price'].mean()\n",
    "Submission_testing['shop_price_mean'] = Submission_testing['shop_id'].map(submit_shop_price_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1220,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train.to_csv(\"TrainPP.csv\", index=False)\n",
    "Submission_testing.to_csv(\"Submission_testingPP.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_price</th>\n",
       "      <th>quantity_sold</th>\n",
       "      <th>shop_area_sq_ft</th>\n",
       "      <th>shop_profile</th>\n",
       "      <th>total_sales</th>\n",
       "      <th>item_description_freq</th>\n",
       "      <th>shop_id_counts</th>\n",
       "      <th>shop_price_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>220.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>678</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>440.0</td>\n",
       "      <td>0.846726</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>211.286307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>112</td>\n",
       "      <td>220.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>668</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>440.0</td>\n",
       "      <td>0.846726</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>204.955641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>160.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>678</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>320.0</td>\n",
       "      <td>0.846726</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>211.286307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>150.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>678</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>300.0</td>\n",
       "      <td>0.846726</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>211.286307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>112</td>\n",
       "      <td>210.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>668</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>0.012887</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>204.955641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  shop_id  item_price  quantity_sold  shop_area_sq_ft shop_profile  \\\n",
       "0       8       220.0            2.0              678     Moderate   \n",
       "1     112       220.0            2.0              668     Moderate   \n",
       "2       8       160.0            2.0              678     Moderate   \n",
       "3       8       150.0            2.0              678     Moderate   \n",
       "4     112       210.0            5.0              668     Moderate   \n",
       "\n",
       "   total_sales item_description_freq shop_id_counts shop_price_mean  \n",
       "0        440.0              0.846726       0.000685      211.286307  \n",
       "1        440.0              0.846726       0.006249      204.955641  \n",
       "2        320.0              0.846726       0.000685      211.286307  \n",
       "3        300.0              0.846726       0.000685      211.286307  \n",
       "4       1050.0              0.012887       0.006249      204.955641  "
      ]
     },
     "execution_count": 1221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate X_train_scaled by shop_id and add all the total_sales values and prevent empty values\n",
    "# Also get the mean of the item_description_freq column\n",
    "Train[\"item_description_freq\"] = Train[\"item_description_freq\"].astype(\"float64\")\n",
    "Submission_testing[\"item_description_freq\"] = Submission_testing[\"item_description_freq\"].astype(\"float64\")\n",
    "Train_cum = Train.groupby(['shop_id'], sort=False).agg({'total_sales':'sum', 'item_description_freq':'mean'})\n",
    "Submission_testing_cum = Submission_testing.groupby(['shop_id'], sort='False').agg({'total_sales':'sum', 'item_description_freq':'mean'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1223,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_cum = Train_cum.merge(StoreInfo, on='shop_id', how='left')\n",
    "Train_cum['shop_id_counts'] = Train_cum['shop_id'].map(train_shop_id_counts)\n",
    "Train_cum['shop_price_mean'] = Train_cum['shop_id'].map(train_shop_price_mean)\n",
    "Train_cum['shop_price_mean'] = Train_cum['shop_price_mean'].astype(\"float64\")\n",
    "\n",
    "Submission_testing_cum = Submission_testing_cum.merge(StoreInfo, on='shop_id', how='left')\n",
    "Submission_testing_cum['shop_id_counts'] = Submission_testing_cum['shop_id'].map(submit_shop_id_counts)\n",
    "Submission_testing_cum['shop_price_mean'] = Submission_testing_cum['shop_id'].map(submit_shop_price_mean)\n",
    "Submission_testing_cum['shop_price_mean'] = Submission_testing_cum['shop_price_mean'].astype(\"float64\")\n",
    "Submission_testing_cum.drop([\"shop_profile\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # new feature: total_sales per sq ft of the shop\n",
    "# Train_cum['sales_per_sq_ft'] = Train_cum['total_sales'] / Train_cum['shop_area_sq_ft']\n",
    "# Submission_testing_cum['sales_per_sq_ft'] = Submission_testing_cum['total_sales'] / Submission_testing_cum['shop_area_sq_ft']\n",
    "\n",
    "# # new feature : difference between the total_sales and total_sales_per_sq_ft\n",
    "# Train_cum['sales_minus_shop_area'] = Train_cum['total_sales'] - Train_cum['shop_area_sq_ft']\n",
    "# Submission_testing_cum['sales_minus_shop_area'] = Submission_testing_cum['total_sales'] - Submission_testing_cum['shop_area_sq_ft']\n",
    "\n",
    "# # new feature: addition of the total_sales and total_sales_per_sq_ft\n",
    "# Train_cum['sales_plus_shop_area'] = Train_cum['total_sales'] + Train_cum['shop_area_sq_ft']\n",
    "# Submission_testing_cum['sales_plus_shop_area'] = Submission_testing_cum['total_sales'] + Submission_testing_cum['shop_area_sq_ft']\n",
    "\n",
    "# # new feature : multiplication of the total_sales and total_sales_per_sq_ft\n",
    "# Train_cum['sales_times_shop_area'] = Train_cum['total_sales'] * Train_cum['shop_area_sq_ft']\n",
    "# Submission_testing_cum['sales_times_shop_area'] = Submission_testing_cum['total_sales'] * Submission_testing_cum['shop_area_sq_ft']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1225,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = Train_cum[\"shop_profile\"]\n",
    "Train_cum.drop(\"shop_profile\", axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_sales</th>\n",
       "      <th>item_description_freq</th>\n",
       "      <th>shop_area_sq_ft</th>\n",
       "      <th>shop_price_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.720947e+06</td>\n",
       "      <td>0.727512</td>\n",
       "      <td>628.290000</td>\n",
       "      <td>207.705220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.535575e+05</td>\n",
       "      <td>0.029402</td>\n",
       "      <td>128.999201</td>\n",
       "      <td>15.787755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.160175e+05</td>\n",
       "      <td>0.572841</td>\n",
       "      <td>298.000000</td>\n",
       "      <td>149.130647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.364278e+06</td>\n",
       "      <td>0.714207</td>\n",
       "      <td>573.250000</td>\n",
       "      <td>197.221343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.699167e+06</td>\n",
       "      <td>0.730701</td>\n",
       "      <td>617.000000</td>\n",
       "      <td>207.379768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.089088e+06</td>\n",
       "      <td>0.746506</td>\n",
       "      <td>676.000000</td>\n",
       "      <td>215.904579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.503605e+06</td>\n",
       "      <td>0.777821</td>\n",
       "      <td>1077.000000</td>\n",
       "      <td>260.227509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total_sales  item_description_freq  shop_area_sq_ft  shop_price_mean\n",
       "count  1.000000e+02             100.000000       100.000000       100.000000\n",
       "mean   1.720947e+06               0.727512       628.290000       207.705220\n",
       "std    5.535575e+05               0.029402       128.999201        15.787755\n",
       "min    1.160175e+05               0.572841       298.000000       149.130647\n",
       "25%    1.364278e+06               0.714207       573.250000       197.221343\n",
       "50%    1.699167e+06               0.730701       617.000000       207.379768\n",
       "75%    2.089088e+06               0.746506       676.000000       215.904579\n",
       "max    3.503605e+06               0.777821      1077.000000       260.227509"
      ]
     },
     "execution_count": 1226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_cum.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_sales</th>\n",
       "      <th>item_description_freq</th>\n",
       "      <th>shop_area_sq_ft</th>\n",
       "      <th>shop_price_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.400000e+01</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.743589e+06</td>\n",
       "      <td>0.731226</td>\n",
       "      <td>585.416667</td>\n",
       "      <td>217.529510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.650631e+05</td>\n",
       "      <td>0.034623</td>\n",
       "      <td>112.998236</td>\n",
       "      <td>14.337272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>9.708300e+05</td>\n",
       "      <td>0.629791</td>\n",
       "      <td>310.000000</td>\n",
       "      <td>194.935012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.308815e+06</td>\n",
       "      <td>0.715052</td>\n",
       "      <td>529.250000</td>\n",
       "      <td>209.509526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.722632e+06</td>\n",
       "      <td>0.736972</td>\n",
       "      <td>607.000000</td>\n",
       "      <td>215.814187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.077289e+06</td>\n",
       "      <td>0.752665</td>\n",
       "      <td>676.000000</td>\n",
       "      <td>228.693990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.636980e+06</td>\n",
       "      <td>0.779407</td>\n",
       "      <td>774.000000</td>\n",
       "      <td>241.754298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total_sales  item_description_freq  shop_area_sq_ft  shop_price_mean\n",
       "count  2.400000e+01              24.000000        24.000000        24.000000\n",
       "mean   1.743589e+06               0.731226       585.416667       217.529510\n",
       "std    4.650631e+05               0.034623       112.998236        14.337272\n",
       "min    9.708300e+05               0.629791       310.000000       194.935012\n",
       "25%    1.308815e+06               0.715052       529.250000       209.509526\n",
       "50%    1.722632e+06               0.736972       607.000000       215.814187\n",
       "75%    2.077289e+06               0.752665       676.000000       228.693990\n",
       "max    2.636980e+06               0.779407       774.000000       241.754298"
      ]
     },
     "execution_count": 1227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Submission_testing_cum.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1228,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaled_columns = [\"total_sales\", \"item_description_freq\", \"shop_area_sq_ft\", \"shop_id_counts\" , \"shop_price_mean\"]\n",
    "ct = ColumnTransformer([(\"MinMaxScaler\", MinMaxScaler(feature_range=(0, 100)), scaled_columns)], remainder=\"passthrough\")\n",
    "\n",
    "scaled_X_train = pd.DataFrame(ct.fit_transform(Train_cum), columns=Train_cum.columns)\n",
    "scaled_X_submission = pd.DataFrame(ct.transform(Submission_testing_cum), columns=Train_cum.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set scaled_X_train shop_id as categorical and other columns as numerical\n",
    "\n",
    "category_columns = [\"shop_id\"]\n",
    "\n",
    "for column in category_columns:\n",
    "    scaled_X_train[column] = scaled_X_train[column].astype(\"category\")\n",
    "    scaled_X_submission[column] = scaled_X_submission[column].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_sales</th>\n",
       "      <th>item_description_freq</th>\n",
       "      <th>shop_area_sq_ft</th>\n",
       "      <th>shop_id_counts</th>\n",
       "      <th>shop_price_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>75.456409</td>\n",
       "      <td>42.399230</td>\n",
       "      <td>56.994608</td>\n",
       "      <td>52.723877</td>\n",
       "      <td>63.410000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.343828</td>\n",
       "      <td>16.559589</td>\n",
       "      <td>18.094525</td>\n",
       "      <td>14.210802</td>\n",
       "      <td>37.976094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>68.965602</td>\n",
       "      <td>35.333761</td>\n",
       "      <td>46.160202</td>\n",
       "      <td>43.287178</td>\n",
       "      <td>31.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>77.012280</td>\n",
       "      <td>40.949936</td>\n",
       "      <td>56.435902</td>\n",
       "      <td>52.430932</td>\n",
       "      <td>62.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>84.722938</td>\n",
       "      <td>48.523748</td>\n",
       "      <td>67.246478</td>\n",
       "      <td>60.104247</td>\n",
       "      <td>95.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>127.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       total_sales  item_description_freq  shop_area_sq_ft  shop_id_counts  \\\n",
       "count   100.000000             100.000000       100.000000      100.000000   \n",
       "mean     75.456409              42.399230        56.994608       52.723877   \n",
       "std      14.343828              16.559589        18.094525       14.210802   \n",
       "min       0.000000               0.000000         0.000000        0.000000   \n",
       "25%      68.965602              35.333761        46.160202       43.287178   \n",
       "50%      77.012280              40.949936        56.435902       52.430932   \n",
       "75%      84.722938              48.523748        67.246478       60.104247   \n",
       "max     100.000000             100.000000       100.000000      100.000000   \n",
       "\n",
       "       shop_price_mean  \n",
       "count       100.000000  \n",
       "mean         63.410000  \n",
       "std          37.976094  \n",
       "min           1.000000  \n",
       "25%          31.750000  \n",
       "50%          62.500000  \n",
       "75%          95.750000  \n",
       "max         127.000000  "
      ]
     },
     "execution_count": 1230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_sales</th>\n",
       "      <th>item_description_freq</th>\n",
       "      <th>shop_area_sq_ft</th>\n",
       "      <th>shop_id_counts</th>\n",
       "      <th>shop_price_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>77.268282</td>\n",
       "      <td>36.895593</td>\n",
       "      <td>250.752305</td>\n",
       "      <td>61.566872</td>\n",
       "      <td>62.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>16.891068</td>\n",
       "      <td>14.505550</td>\n",
       "      <td>66.018390</td>\n",
       "      <td>12.905200</td>\n",
       "      <td>32.095871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>27.783031</td>\n",
       "      <td>1.540436</td>\n",
       "      <td>134.800148</td>\n",
       "      <td>41.229215</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>69.377643</td>\n",
       "      <td>29.685494</td>\n",
       "      <td>211.893757</td>\n",
       "      <td>54.347961</td>\n",
       "      <td>36.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>80.071591</td>\n",
       "      <td>39.666239</td>\n",
       "      <td>257.093212</td>\n",
       "      <td>60.022883</td>\n",
       "      <td>65.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>87.727349</td>\n",
       "      <td>48.523748</td>\n",
       "      <td>281.409131</td>\n",
       "      <td>71.616193</td>\n",
       "      <td>88.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>100.773547</td>\n",
       "      <td>61.103979</td>\n",
       "      <td>396.123959</td>\n",
       "      <td>83.371978</td>\n",
       "      <td>114.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       total_sales  item_description_freq  shop_area_sq_ft  shop_id_counts  \\\n",
       "count    24.000000              24.000000        24.000000       24.000000   \n",
       "mean     77.268282              36.895593       250.752305       61.566872   \n",
       "std      16.891068              14.505550        66.018390       12.905200   \n",
       "min      27.783031               1.540436       134.800148       41.229215   \n",
       "25%      69.377643              29.685494       211.893757       54.347961   \n",
       "50%      80.071591              39.666239       257.093212       60.022883   \n",
       "75%      87.727349              48.523748       281.409131       71.616193   \n",
       "max     100.773547              61.103979       396.123959       83.371978   \n",
       "\n",
       "       shop_price_mean  \n",
       "count        24.000000  \n",
       "mean         62.666667  \n",
       "std          32.095871  \n",
       "min           2.000000  \n",
       "25%          36.000000  \n",
       "50%          65.500000  \n",
       "75%          88.250000  \n",
       "max         114.000000  "
      ]
     },
     "execution_count": 1231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_X_submission.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1232,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Splitting the dataset into the Training set and Test set\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_X_train, y_train, test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import labelencoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train = pd.DataFrame(y_train)\n",
    "# y_test = pd.DataFrame(y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1245,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def score_classification(model, df1_x, df1_y, df2_x, df2_y):\n",
    "  print(model)\n",
    "  df1_x = df1_x.copy()\n",
    "  df2_x = df2_x.copy() \n",
    "  ct2 = ColumnTransformer(transformers=[('encoder', OneHotEncoder(handle_unknown='ignore'), [0])], remainder='passthrough')\n",
    "\n",
    "  # One hot encoding for the item_description column\n",
    "\n",
    "  df1_encoded = ct2.fit_transform(df1_x[[\"shop_id\"]])\n",
    "  df1_x = pd.concat([df1_x.drop(\"shop_id\", axis=1).reset_index(drop=True), pd.DataFrame(df1_encoded.toarray())], axis='columns')\n",
    "\n",
    "  df2_encoded = ct2.transform(df2_x[[\"shop_id\"]])\n",
    "  df2_x = pd.concat([df2_x.drop(\"shop_id\", axis=1).reset_index(drop=True), pd.DataFrame(df2_encoded.toarray())], axis='columns')\n",
    "\n",
    "  # remove the dummy variable trap\n",
    "  df1_x = df1_x.drop([0], axis=1)\n",
    "  df2_x = df2_x.drop([0], axis=1)\n",
    "  \n",
    "  df1_x.columns = df1_x.columns.astype(str)\n",
    "  df2_x.columns = df2_x.columns.astype(str)\n",
    "  # Fit the model  \n",
    "  model.fit(df1_x, df1_y)\n",
    "\n",
    "  # Make predictions\n",
    "  y_pred = model.predict(df2_x)\n",
    "  print(df2_y)\n",
    "  print(y_pred)\n",
    "  # Evaluate the model\n",
    "  # accuracy = accuracy_score(df2_y, y_pred)\n",
    "  # precision = precision_score(df2_y, y_pred,  average='macro')\n",
    "  # recall = recall_score(df2_y, y_pred,  average='macro')\n",
    "  # f1 = f1_score(df2_y, y_pred,  average='macro')\n",
    "\n",
    "  # print(f\"Accuracy: {accuracy}\")\n",
    "  # print(f\"Precision: {precision}\")\n",
    "  # print(f\"Recall: {recall}\")\n",
    "  # print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outputResult(model, df1_x, df1_y, test, le):\n",
    "    print(model)\n",
    "    df1_x = df1_x.copy()\n",
    "    df2_x = test.copy()\n",
    "    \n",
    "    ct2 = ColumnTransformer(transformers=[('encoder', OneHotEncoder(handle_unknown='ignore'), [0])], remainder='passthrough')\n",
    "\n",
    "    # One hot encoding for the item_description column\n",
    "\n",
    "    df1_encoded = ct2.fit_transform(df1_x[[\"shop_id\"]])\n",
    "    df1_x = pd.concat([df1_x.drop(\"shop_id\", axis=1).reset_index(drop=True), pd.DataFrame(df1_encoded.toarray())], axis='columns')\n",
    "\n",
    "    df2_encoded = ct2.transform(df2_x[[\"shop_id\"]])\n",
    "    df2_x = pd.concat([df2_x.drop(\"shop_id\", axis=1).reset_index(drop=True), pd.DataFrame(df2_encoded.toarray())], axis='columns')\n",
    "\n",
    "  # Drop the first column to avoid dummy variable trap\n",
    "    df1_x = df1_x.drop([0], axis=1)\n",
    "    df2_x = df2_x.drop([0], axis=1)\n",
    "\n",
    "    # remove the dummy variable trap\n",
    "    df1_x = df1_x.drop([0], axis=1)\n",
    "    df2_x = df2_x.drop([0], axis=1)\n",
    "  \n",
    "    # Fit the model on the training data\n",
    "    model.fit(df1_x, df1_y)\n",
    "    \n",
    "    # Make predictions on the test data\n",
    "    y_pred = model.predict(df2_x)\n",
    "    \n",
    "    # Inverse transform the encoded predictions to the original shop profiles\n",
    "    y_pred = le.inverse_transform(y_pred)    \n",
    "    \n",
    "    # Create a dataframe with the predicted shop profiles\n",
    "    results_df = pd.DataFrame({'shop_id': test.shop_id, 'shop_profile': y_pred})    \n",
    "    # rename the shop_id column with the word \"SHOP\" and add a 0 in front of the shop_id\n",
    "    results_df[\"shop_id\"] = results_df[\"shop_id\"].astype(int).astype(str)\n",
    "    results_df[\"shop_id\"] = \"SHOP\" + results_df[\"shop_id\"].str.zfill(3)\n",
    "\n",
    "    # results_df.drop_duplicates(inplace=True)\n",
    "    \n",
    "    # Access the global testing dataframe\n",
    "    results_final = pd.merge(Testing, results_df, on=\"shop_id\", how=\"left\")\n",
    "    # Write the dataframe to a CSV file\n",
    "    results_final.to_csv('predictions'+str(model).strip(\"()\")+'.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1237,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression()\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Mix of label input types (string and number)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1242], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m score_classification(logr, X_train, y_train, X_test, y_test)\n",
      "Cell \u001b[1;32mIn[1241], line 32\u001b[0m, in \u001b[0;36mscore_classification\u001b[1;34m(model, df1_x, df1_y, df2_x, df2_y)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[39m# Evaluate the model\u001b[39;00m\n\u001b[0;32m     31\u001b[0m accuracy \u001b[39m=\u001b[39m accuracy_score(df2_y, y_pred)\n\u001b[1;32m---> 32\u001b[0m precision \u001b[39m=\u001b[39m precision_score(df2_y, y_pred,  average\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmacro\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     33\u001b[0m recall \u001b[39m=\u001b[39m recall_score(df2_y, y_pred,  average\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmacro\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     34\u001b[0m f1 \u001b[39m=\u001b[39m f1_score(df2_y, y_pred,  average\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmacro\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1954\u001b[0m, in \u001b[0;36mprecision_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1825\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprecision_score\u001b[39m(\n\u001b[0;32m   1826\u001b[0m     y_true,\n\u001b[0;32m   1827\u001b[0m     y_pred,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1833\u001b[0m     zero_division\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwarn\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1834\u001b[0m ):\n\u001b[0;32m   1835\u001b[0m     \u001b[39m\"\"\"Compute the precision.\u001b[39;00m\n\u001b[0;32m   1836\u001b[0m \n\u001b[0;32m   1837\u001b[0m \u001b[39m    The precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1952\u001b[0m \u001b[39m    array([0.5, 1. , 1. ])\u001b[39;00m\n\u001b[0;32m   1953\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1954\u001b[0m     p, _, _, _ \u001b[39m=\u001b[39m precision_recall_fscore_support(\n\u001b[0;32m   1955\u001b[0m         y_true,\n\u001b[0;32m   1956\u001b[0m         y_pred,\n\u001b[0;32m   1957\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[0;32m   1958\u001b[0m         pos_label\u001b[39m=\u001b[39;49mpos_label,\n\u001b[0;32m   1959\u001b[0m         average\u001b[39m=\u001b[39;49maverage,\n\u001b[0;32m   1960\u001b[0m         warn_for\u001b[39m=\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mprecision\u001b[39;49m\u001b[39m\"\u001b[39;49m,),\n\u001b[0;32m   1961\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   1962\u001b[0m         zero_division\u001b[39m=\u001b[39;49mzero_division,\n\u001b[0;32m   1963\u001b[0m     )\n\u001b[0;32m   1964\u001b[0m     \u001b[39mreturn\u001b[39;00m p\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1573\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1571\u001b[0m \u001b[39mif\u001b[39;00m beta \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1572\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mbeta should be >=0 in the F-beta score\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 1573\u001b[0m labels \u001b[39m=\u001b[39m _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n\u001b[0;32m   1575\u001b[0m \u001b[39m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[0;32m   1576\u001b[0m samplewise \u001b[39m=\u001b[39m average \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msamples\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1377\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1374\u001b[0m y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[0;32m   1375\u001b[0m \u001b[39m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[39;00m\n\u001b[0;32m   1376\u001b[0m \u001b[39m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[39;00m\n\u001b[1;32m-> 1377\u001b[0m present_labels \u001b[39m=\u001b[39m unique_labels(y_true, y_pred)\u001b[39m.\u001b[39mtolist()\n\u001b[0;32m   1378\u001b[0m \u001b[39mif\u001b[39;00m average \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m   1379\u001b[0m     \u001b[39mif\u001b[39;00m y_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\utils\\multiclass.py:117\u001b[0m, in \u001b[0;36munique_labels\u001b[1;34m(*ys)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[39m# Check that we don't mix string type with number type\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mset\u001b[39m(\u001b[39misinstance\u001b[39m(label, \u001b[39mstr\u001b[39m) \u001b[39mfor\u001b[39;00m label \u001b[39min\u001b[39;00m ys_labels)) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mMix of label input types (string and number)\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    119\u001b[0m \u001b[39mreturn\u001b[39;00m xp\u001b[39m.\u001b[39masarray(\u001b[39msorted\u001b[39m(ys_labels))\n",
      "\u001b[1;31mValueError\u001b[0m: Mix of label input types (string and number)"
     ]
    }
   ],
   "source": [
    "score_classification(logr, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtc = DecisionTreeClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "score_classification(dtc, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "rfc = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameters to test\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'max_depth': [5, 10, 15, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Use grid search cross-validation to find the best hyperparameters\n",
    "# grid_search = GridSearchCV(estimator=rfc, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# # Print the best hyperparameters and the corresponding accuracy score\n",
    "# print(\"Best Hyperparameters: \", grid_search.best_params_)\n",
    "# print(\"Best Accuracy Score: \", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc.set_params(max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_classification(rfc, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC(kernel='linear', C=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_classification(svm, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_classification(gbm, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_classification(knn, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "\n",
    "# Define the parameter grid to search over\n",
    "param_grid = {\n",
    "    'knn__n_neighbors': [3, 5, 7, 9, 11],\n",
    "    'knn__weights': ['uniform', 'distance'],\n",
    "    'knn__p': [1, 2],\n",
    "    'knn__algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "    'knn__leaf_size': [10, 20, 30, 40, 50],\n",
    "    'knn__metric': ['euclidean', 'manhattan', 'chebyshev', 'minkowski']\n",
    "}\n",
    "\n",
    "# Create a pipeline to preprocess the data and apply KNN\n",
    "pipeline = Pipeline([ \n",
    "    ('knn', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "# Create a grid search object to find the best parameters\n",
    "grid_search_knn = GridSearchCV(pipeline, param_grid, cv=5, n_jobs=-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fit the grid search object on the data\n",
    "# grid_search_knn.fit(X_train, y_train)\n",
    "\n",
    "# # Print the best parameters found\n",
    "# print(\"Best parameters:\", grid_search_knn.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5, shuffle=False).split(range(25))\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "knn2 = KNeighborsClassifier(n_neighbors=5)\n",
    "scores = cross_val_score(knn, X_train, y_train, cv=10, scoring='f1_macro')\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the best parameters found by GridSearchCV\n",
    "knn.set_params(**{'algorithm': 'auto', 'leaf_size': 10, 'metric': 'euclidean', 'n_neighbors': 5, 'p': 1, 'weights': 'distance'})\n",
    "\n",
    "score_classification(knn, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(rfc, X_train, y_train, cv=10, scoring='accuracy')\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nb = GaussianNB()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "score_classification(nb, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(objective='binary:logistic', n_estimators=100, max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_classification(xgb_model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# score_classification(xgb_model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of classifiers to compare\n",
    "classifiers = [logr, dtc, knn, rfc, nb, svm, gbm]\n",
    "\n",
    "# Create X and y data\n",
    "\n",
    "# Cross-validation\n",
    "for clf in classifiers:\n",
    "    scores = cross_val_score(clf, X_train, y_train, cv=5, scoring=lambda clf, X, y: f1_score(y, clf.predict(X), average='macro'))\n",
    "    print(clf.__class__.__name__)\n",
    "    print(\"F1 Score: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "def make_mi_scores(X,y):\n",
    "  X = X.copy()\n",
    "  for colname in X.select_dtypes([\"object\", \"category\"]):\n",
    "    X[colname], _ = X[colname].factorize()\n",
    "  # all discrete features should now have integer dtypes\n",
    "  discrete_features = [pd.api.types.is_integer_dtype(t) for t in X.dtypes]\n",
    "  mi_scores = mutual_info_regression(X, y, discrete_features=discrete_features, random_state=0)\n",
    "  mi_scores = pd.Series(mi_scores, name=\"Mutual Information Scores\", index=X.columns)\n",
    "  mi_scores = mi_scores.sort_values(ascending=False)\n",
    "  return mi_scores\n",
    "\n",
    "\n",
    "def plot_mi_scores(scores):\n",
    "  scores = scores.sort_values(ascending=True)\n",
    "  width = np.arange(len(scores))\n",
    "  ticks = list(scores.index)\n",
    "  plt.barh(width,scores)\n",
    "  plt.yticks(width, ticks)\n",
    "  plt.title(\"Mututal Information Scores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no of null values in each column\n",
    "# print(y_train.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mi_scores = make_mi_scores(X_train, y_train)\n",
    "# mi_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def apply_pca(X):\n",
    "  pca= PCA()\n",
    "  df1_x = X.copy()\n",
    "\n",
    "  X_pca = pca.fit_transform(df1_x)\n",
    "  component_names = [f\"PC{i+1}\" for i in range(X_pca.shape[1])]\n",
    "  X_pca = pd.DataFrame(X_pca, columns=component_names)\n",
    "  #create loadings\n",
    "  loadings = pd.DataFrame(\n",
    "  pca.components_.T,\n",
    "  columns = component_names,\n",
    "  index=df1_x.columns,\n",
    "  )\n",
    "  return pca, X_pca, loadings\n",
    "\n",
    "def plot_variance(pca, width=8, dpi=100):\n",
    "  fig, axs = plt.subplots(1,2)\n",
    "  n = pca.n_components_\n",
    "  grid = np.arange(1, n+1)\n",
    "  evr = pca.explained_variance_ratio_\n",
    "  axs[0].bar(grid,evr)\n",
    "  axs[0].set(\n",
    "      xlabel=\"Component\",title=\"% Explained Variance\", ylim=(0.0,1.0)             )\n",
    "  #Cumulative Variance\n",
    "  cv = np.cumsum(evr)\n",
    "  axs[1].plot(np.r_[0,grid], np.r_[0,cv], \"o-\")\n",
    "  axs[1].set(xlabel=\"Component\", title=\"% Cumulatve Variance\", ylim=(0.0, 1.0))\n",
    "  fig.set(figwidth=8, dpi=100)\n",
    "  return axs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"shop_id\"].astype(\"int\").astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # plot a pairplot for all the features\n",
    "y_train_df = pd.DataFrame(y_train, columns=['target'])\n",
    "# X_train.index = range(len(X_train))\n",
    "# combine X_train and y_train into a single dataframe\n",
    "df_concat = pd.concat([X_train, y_train_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create the pairplot\n",
    "# sns.pairplot(df_concat, hue='target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def cluster_labels(df, features, n_clusters=6):\n",
    "  X = df.copy()\n",
    "  X_new = X.loc[:, features]\n",
    "  kmeans = KMeans(n_clusters=n_clusters, n_init=100, random_state=0)\n",
    "  X_new[\"Cluster\"] = kmeans.fit_predict(X_new)\n",
    "  X_new[\"Cluster\"] = X_new.Cluster.astype(\"category\")\n",
    "  return X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cluster(X, y):\n",
    "  Xy = X.copy()\n",
    "  Xy[\"y\"] = y\n",
    "  Xy.head()\n",
    "  sns.relplot(\n",
    "      x=\"value\", y=\"y\", hue=\"Cluster\", col=\"variable\",\n",
    "      height=4, aspect=1, facet_kws={'sharex':False}, col_wrap=3,\n",
    "      data=Xy.melt(\n",
    "          value_vars=features, id_vars=[\"y\", \"Cluster\"]\n",
    "      )\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = X_train.columns\n",
    "cluster_df1_x = cluster_labels(X_train, features, n_clusters=3)\n",
    "cluster_df2_x = cluster_labels(X_test, features, n_clusters=3)\n",
    "# cluster_df3_x = cluster_labels(Submission_testing, features, n_clusters=3)\n",
    "cluster_df1_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cluster(cluster_df1_x, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_classification(rfc, cluster_df1_x, y_train, cluster_df2_x, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster_df1_x.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster_df1_x.drop(['shop_area_sq_ft'], axis=1, inplace=True)\n",
    "# cluster_df2_x.drop(['shop_area_sq_ft'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster_df1_x.drop(columns=['sales_plus_shop_area', 'sales_minus_shop_area', 'unique_items'], axis=1, inplace=True)\n",
    "# cluster_df2_x.drop(columns=['sales_plus_shop_area', 'sales_minus_shop_area', 'unique_items'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_classification(knn, cluster_df1_x, y_train, cluster_df2_x, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca, X_pca, loadings = apply_pca(X_train)\n",
    "# print(loadings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_classification(gbm, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(columns=['sales_plus_shop_area'], axis=1, inplace=True)\n",
    "X_test.drop(columns=['sales_plus_shop_area'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_classification(gbm, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(columns=['sales_minus_shop_area'], axis=1, inplace=True)\n",
    "X_test.drop(columns=['sales_minus_shop_area'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_classification(dtc, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for clf in classifiers:\n",
    "    scores = cross_val_score(clf, X_train, y_train, cv=5, scoring=lambda clf, X, y: f1_score(y, clf.predict(X), average='macro'))\n",
    "    print(clf.__class__.__name__)\n",
    "    print(\"F1 Score: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_classification(dtc, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(columns=['unique_items', 'order_count'], axis=1, inplace=True)\n",
    "X_test.drop(columns=['unique_items', 'order_count'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_classification(dtc, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_classification(rfc, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X_submission = scaled_X_submission[X_train.columns]\n",
    "outputResult(dtc, X_train, y_train, scaled_X_submission, le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_classification(rfc, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(columns=['shop_area_sq_ft'], axis=1, inplace=True)\n",
    "X_test.drop(columns=['shop_area_sq_ft'], axis=1, inplace=True)\n",
    "for clf in classifiers:\n",
    "    scores = cross_val_score(clf, X_train, y_train, cv=5, scoring=lambda clf, X, y: f1_score(y, clf.predict(X), average='macro'))\n",
    "    print(clf.__class__.__name__)\n",
    "    print(\"F1 Score: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_classification(knn, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(columns=['order_count', 'unique_items'], axis=1, inplace=True)\n",
    "X_test.drop(columns=['order_count', 'unique_items'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for clf in classifiers:\n",
    "    scores = cross_val_score(clf, X_train, y_train, cv=5, scoring=lambda clf, X, y: f1_score(y, clf.predict(X), average='macro'))\n",
    "    print(clf.__class__.__name__)\n",
    "    print(\"F1 Score: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaled_X_submission = scaled_X_submission[X_train.columns]\n",
    "# outputResult(gbm, X_train, y_train, scaled_X_submission, le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameters to test\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'max_depth': [5, 10, 15, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use grid search cross-validation to find the best hyperparameters\n",
    "grid_search = GridSearchCV(estimator=rfc, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters and the corresponding accuracy score\n",
    "print(\"Best Hyperparameters: \", grid_search.best_params_)\n",
    "print(\"Best Accuracy Score: \", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rfc.set_params(**grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_classification(rfc, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the grid search object on the data\n",
    "# grid_search_knn.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Print the best parameters found\n",
    "# print(\"Best parameters:\", grid_search_knn.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn.set_params(**{'algorithm': 'auto', 'leaf_size': 10, 'metric': 'euclidean', 'n_neighbors': 11, 'p': 1, 'weights': 'uniform'})\n",
    "knn.set_params(**{'algorithm': 'auto', 'leaf_size': 10, 'metric': 'euclidean', 'n_neighbors': 5, 'p': 1, 'weights': 'distance'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_classification(dtc, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_classification(knn, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_classification(nb, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_classification(dtc, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X_submission = scaled_X_submission[X_train.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputResult(knn, X_train, y_train, scaled_X_submission, le)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
